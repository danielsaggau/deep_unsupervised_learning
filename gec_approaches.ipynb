{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gec_approaches.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpBELuPSKQHjR5Oi0inuCk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/deep_unsupervised_learning/blob/master/gec_approaches.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6J8Lj3VjDPs",
        "outputId": "5ae5b135-fcae-405a-c951-61ba188a2d5b"
      },
      "source": [
        "!git clone https://github.com/grammarly/gector.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gector'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 86 (delta 29), reused 24 (delta 24), pack-reused 43\u001b[K\n",
            "Unpacking objects: 100% (86/86), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BWryzQYjRFz"
      },
      "source": [
        "%cd gector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6O3PLenjM9Y"
      },
      "source": [
        "train.py --train_set TRAIN_SET --dev_set DEV_SET \\\n",
        "                --model_dir MODEL_DIR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNW3--N_oyCo"
      },
      "source": [
        "/data/A.train.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ1i5EHOE-2t",
        "outputId": "953fdd0a-e78f-4106-f1c4-8aaf937ec3ef"
      },
      "source": [
        "!git clone https://github.com/kakaobrain/helo_word.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'helo_word'...\n",
            "remote: Enumerating objects: 259, done.\u001b[K\n",
            "remote: Total 259 (delta 0), reused 0 (delta 0), pack-reused 259\u001b[K\n",
            "Receiving objects: 100% (259/259), 4.19 MiB | 22.02 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKu05hGFFIwP",
        "outputId": "ee3214ba-450e-4468-bcfa-a7c8686edc6e"
      },
      "source": [
        "%cd helo_word/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/helo_word\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNfsaf6cFSxs"
      },
      "source": [
        "# apt-get packages (required for hunspell & pattern)\n",
        "!apt-get update\n",
        "!apt-get install libhunspell-dev libmysqlclient-dev -y\n",
        "\n",
        "# pip packages\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade -r requirements.txt\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC7tWJ1RFZ8W",
        "outputId": "40582aa6-3527-4d67-e80f-36e40df060cc"
      },
      "source": [
        "# custom fairseq (fork of 0.6.1 with gec modifications)\n",
        "!pip install --editable fairseq"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/helo_word/fairseq\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.6.1) (1.14.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.6.1) (1.19.5)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from fairseq==0.6.1) (1.5.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.6.1) (4.61.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.6.1) (2.20)\n",
            "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->fairseq==0.6.1) (2.0.0)\n",
            "Installing collected packages: fairseq\n",
            "  Attempting uninstall: fairseq\n",
            "    Found existing installation: fairseq 0.6.1\n",
            "    Can't uninstall 'fairseq'. No files were found to uninstall.\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed fairseq-0.6.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7nWOGLGFcL1"
      },
      "source": [
        "# errant\n",
        "!git clone https://github.com/chrisjbryant/errant\n",
        "\n",
        "# pattern3 (see https://www.clips.uantwerpen.be/pages/pattern for any installation issues)\n",
        "!pip install pattern3\n",
        "!python -c \"import site; print(site.getsitepackages())\"\n",
        "# ['PATH_TO_SITE_PACKAGES']\n",
        "!cp tree.py PATH_TO_SITE_PACKAGES/pattern3/text/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfltoUWbGUmt",
        "outputId": "0eeb4a29-bb74-4c8d-d259-a3a1ee6605cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python preprocess.py"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"preprocess.py\", line 5, in <module>\n",
            "    from gec import filepath, word_tokenize, bpe, perturb, m2, spell\n",
            "  File \"/content/helo_word/gec/word_tokenize.py\", line 3, in <module>\n",
            "    import spacy # 1.9\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/spacy/__init__.py\", line 10, in <module>\n",
            "    from thinc.neural.util import prefer_gpu, require_gpu\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/__init__.py\", line 4, in <module>\n",
            "    from ._classes.model import Model  # noqa: F401\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/_classes/model.py\", line 11, in <module>\n",
            "    from ..train import Trainer\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/thinc/neural/train.py\", line 7, in <module>\n",
            "    from .optimizers import Adam, linear_decay\n",
            "  File \"optimizers.pyx\", line 14, in init thinc.neural.optimizers\n",
            "  File \"cymem.pxd\", line 4, in init thinc.neural.ops\n",
            "AttributeError: module 'cymem.cymem' has no attribute 'PyMalloc'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwnC5GysKADd"
      },
      "source": [
        "!git clone https://github.com/Katsumata420/generic-pretrained-GEC.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSKJafFhKYyk",
        "outputId": "38af52f6-f307-4b15-85d8-b5a3002dd023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/Gideon-Stein/On-grammar-improvements-of-GPT-2-generation.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'On-grammar-improvements-of-GPT-2-generation'...\n",
            "remote: Enumerating objects: 272, done.\u001b[K\n",
            "remote: Counting objects: 100% (272/272), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 272 (delta 135), reused 257 (delta 123), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (272/272), 8.84 MiB | 12.00 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcNM3yKQKiC9",
        "outputId": "c299a5a6-3619-47cc-a737-494be9ac1519",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -r requirements.txt\n",
        "%cd /content/helo_word/On-grammar-improvements-of-GPT-2-generation"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy==1.9.0\n",
            "  Using cached spacy-1.9.0.tar.gz (3.4 MB)\n",
            "Collecting hunspell\n",
            "  Using cached hunspell-0.5.5-cp37-cp37m-linux_x86_64.whl\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Using cached sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (4.61.2)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.6.4)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: murmurhash<0.27,>=0.26 in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (0.26.4)\n",
            "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (1.31.2)\n",
            "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Collecting thinc<6.6.0,>=6.5.0\n",
            "  Using cached thinc-6.5.2.tar.gz (926 kB)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (0.9.6)\n",
            "Collecting pip<10.0.0,>=9.0.0\n",
            "  Using cached pip-9.0.3-py2.py3-none-any.whl (1.4 MB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: pathlib in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Collecting ujson>=1.35\n",
            "  Using cached ujson-4.0.2-cp37-cp37m-manylinux1_x86_64.whl (179 kB)\n",
            "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (0.2.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==1.9.0->-r requirements.txt (line 1)) (2.23.0)\n",
            "Collecting regex<2017.12.1,>=2017.4.1\n",
            "  Using cached regex-2017.11.9-cp37-cp37m-linux_x86_64.whl\n",
            "Collecting ftfy<5.0.0,>=4.4.2\n",
            "  Using cached ftfy-4.4.3-py3-none-any.whl\n",
            "Requirement already satisfied: html5lib in /usr/local/lib/python3.7/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy==1.9.0->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy<5.0.0,>=4.4.2->spacy==1.9.0->-r requirements.txt (line 1)) (0.2.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==1.9.0->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==1.9.0->-r requirements.txt (line 1)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==1.9.0->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==1.9.0->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (from thinc<6.6.0,>=6.5.0->spacy==1.9.0->-r requirements.txt (line 1)) (1.12.1)\n",
            "Collecting cytoolz<0.9,>=0.8\n",
            "  Using cached cytoolz-0.8.2.tar.gz (386 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from thinc<6.6.0,>=6.5.0->spacy==1.9.0->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from cytoolz<0.9,>=0.8->thinc<6.6.0,>=6.5.0->spacy==1.9.0->-r requirements.txt (line 1)) (0.11.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from html5lib->ftfy<5.0.0,>=4.4.2->spacy==1.9.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Building wheels for collected packages: spacy, thinc, cytoolz\n",
            "  Building wheel for spacy (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for spacy\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for spacy\n",
            "  Building wheel for thinc (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for thinc\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for thinc\n",
            "  Building wheel for cytoolz (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for cytoolz\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for cytoolz\n",
            "Failed to build spacy thinc cytoolz\n",
            "Installing collected packages: cytoolz, ujson, thinc, regex, pip, ftfy, spacy, sentencepiece, hunspell\n",
            "    Running setup.py install for cytoolz ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-tgvgrrra/cytoolz_91ae8fb35c4246ed95b7306036b5559b/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-tgvgrrra/cytoolz_91ae8fb35c4246ed95b7306036b5559b/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-t7co2su4/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/cytoolz Check the logs for full command output.\u001b[0m\n",
            "/content/helo_word/On-grammar-improvements-of-GPT-2-generation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bFM-_dDKzTl"
      },
      "source": [
        "!python create_empty_folders.py"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BICspNjpLHHd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}